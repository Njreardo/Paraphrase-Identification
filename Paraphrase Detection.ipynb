{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "delayed-treatment",
   "metadata": {},
   "source": [
    "## Paraphrase Identification\n",
    "#### Nick Reardon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tight-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "immune-oakland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236736"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wds = words.words()\n",
    "len(wds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "early-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(string):\n",
    "    \n",
    "    remove = \"~!@#$%^&*()_+`-={}|[]\\\\:\\\";'<>?,.//*-+.'\"\n",
    "    \n",
    "    for u in remove:\n",
    "        try:\n",
    "            string = string.replace(u,'')\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    tokens = []\n",
    "    for u in string.lower().split(' '):\n",
    "        tokens.append(stemmer.stem(u))\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accessory-sociology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anymore', 'any_longer']\n"
     ]
    }
   ],
   "source": [
    "word = 'anymore'\n",
    "\n",
    "for synonym in wordnet.synsets(word):\n",
    "    print(synonym.lemma_names())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "tutorial-curve",
   "metadata": {},
   "source": [
    "synonyms = {}\n",
    "for word in wds:\n",
    "    synonyms[word] = []\n",
    "    for synonym in wordnet.synsets(word):\n",
    "        for syn in synonym.lemma_names():\n",
    "            syns = normalize(syn)\n",
    "            word = normalize(word)[0]\n",
    "            for u in syns:\n",
    "                if word not in synonyms:\n",
    "                    synonyms[word] = []\n",
    "                try:\n",
    "                    if u not in synonyms[word]:\n",
    "                        synonyms[word].append(u.lower())\n",
    "                except:\n",
    "                    synonyms[word].append(u)\n",
    "                if u not in synonyms:\n",
    "                    synonyms[u] = [u]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affecting-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "classical-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms = pickle.load(open('English Synonyms.p','rb'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "infrared-budapest",
   "metadata": {},
   "source": [
    "pickle.dump(synonyms, open('English Synonyms.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "electoral-hudson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is Pattern Recognition?\n",
    "original_phrase = \"The ability to determine the statistical impracticality of randomness.\"\n",
    "\n",
    "# Let's normalize that for ease of detecting a paraphrase\n",
    "original_phrase = normalize(original_phrase)\n",
    "\n",
    "# What is another way to say what Pattern Recognition is?\n",
    "paraphrase = \"The power to ascertain the statistical unfeasability of chaos.\"\n",
    "\n",
    "# Again, let's normalize that.\n",
    "paraphrase = normalize(paraphrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dutch-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we stem the phrases and convert them to individual parts (tokens) in a list so that we can treat these phrases as objects to be statistically analyzed\n",
    "root_phrase = [stemmer.stem(i) for i in original_phrase]\n",
    "root_paraphrase = [stemmer.stem(i) for i in paraphrase]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-president",
   "metadata": {},
   "source": [
    "### General EDA\n",
    "#### Just taking a look at all of our (stemmed) synonym options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "binding-documentary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the \n",
      "\n",
      "abil: ['abil', 'power'] \n",
      "\n",
      "to \n",
      "\n",
      "determin: ['determin', 'determiningfactor', 'causalfactor', 'antigenicdetermin', 'epitop', 'decid', 'definit', 'find', 'purpos', 'decis', 'conclus', 'findout', 'ascertain', 'shape', 'mold', 'influenc', 'regul', 'set', 'specifi', 'defin', 'fix', 'limit', 'makeuponesmind', 'settl', 'squareoff', 'squareup', 'check', 'see', 'watch', 'learn', 'dictat', 'compuls', 'driven', 'unfalt', 'unshak', 'ambiti', 'clincher'] \n",
      "\n",
      "the \n",
      "\n",
      "statist: ['statist'] \n",
      "\n",
      "impract: ['impract', 'impractic', 'infeas', 'unfeas', 'unwork', 'airi', 'visionari', 'laputan', 'windi'] \n",
      "\n",
      "of \n",
      "\n",
      "random: ['random', 'randomis', 'indiscrimin', 'haphazard', 'willynilli', 'arbitrarili', 'atrandom', 'everywhichway', 'entropi', 's', 'stochast', 'nois'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for u in root_phrase:\n",
    "    try:\n",
    "        if len(synonyms[u]) == 0:\n",
    "            print (u, \"\\n\")\n",
    "        else:\n",
    "            print(u+':', synonyms[u], \"\\n\")\n",
    "    except:\n",
    "        print(u, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "hindu-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the \n",
      "\n",
      "power: ['power', 'abil', 'offic', 'forc', 'expon', 'index', 'might', 'mighti', 'worldpow', 'majorpow', 'greatpow', 'superpow', 'baron', 'bigbusinessman', 'businesslead', 'king', 'magnat', 'mogul', 'topexecut', 'tycoon'] \n",
      "\n",
      "to \n",
      "\n",
      "ascertain: ['determin', 'find', 'findout', 'ascertain', 'see', 'check', 'insur', 'seetoit', 'ensur', 'control', 'assur', 'watch', 'learn', 'discover'] \n",
      "\n",
      "the \n",
      "\n",
      "statist: ['statist'] \n",
      "\n",
      "unfea: ['unfeas', 'infeas', 'unwork'] \n",
      "\n",
      "of \n",
      "\n",
      "chao: ['chao', 'pandemonium', 'bedlam', 'topsyturvydom', 'topsyturvy'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for u in root_paraphrase:\n",
    "    try:\n",
    "        if len(synonyms[u]) == 0:\n",
    "            print (u, \"\\n\")\n",
    "        else:\n",
    "            print(u+':', synonyms[u], \"\\n\")\n",
    "    except:\n",
    "        print(u, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "novel-ecology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9\n"
     ]
    }
   ],
   "source": [
    "# We see that the length of each tokenized object is a 9. This will not always be the case but, for demonstration purposes, it is somewhat easy.\n",
    "\n",
    "print(len(root_phrase), len(root_paraphrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thermal-average",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match!\n",
      "Match!\n",
      "Match!\n",
      "Match!\n",
      "Match!\n",
      "Match!\n",
      "Match!\n"
     ]
    }
   ],
   "source": [
    "# Since we are seeing something like what we see above, where randomness may not be a word in this dictionary, we have to do a little math.\n",
    "# Here's one way we can do this\n",
    "n = 0\n",
    "i = 0\n",
    "for u in root_phrase:\n",
    "    if root_paraphrase[i] in synonyms[u]:\n",
    "        print(\"Match!\")\n",
    "        n += 1\n",
    "    elif u == root_paraphrase[i]:\n",
    "        print(\"Match!\")\n",
    "        n += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "otherwise-centre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We've found 7 matches! That is 7 out of 9 objects in our data that can be used to calculate whether it should be treated as a paraphrase or not.\n",
    "\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ideal-techno",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_of_paraphrase = n / len(root_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "corresponding-ferry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likelihood_of_paraphrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "statutory-python",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is likely a paraphrase!\n"
     ]
    }
   ],
   "source": [
    "# I guess that at this point we should determine a threshold for when to call something a paraphrase of the original phrase.\n",
    "# For now let's just use a naive threshold. 75%\n",
    "\n",
    "if likelihood_of_paraphrase > .75:\n",
    "    print('This is likely a paraphrase!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-austin",
   "metadata": {},
   "source": [
    "#### Good news! This is likely a match! Let's treat it as if it is (as we already know that it is).\n",
    "#### Now let's build a function that we can call on for any two inputs to see if we have a paraphrase or not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "level-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're going to import this function to a different script remember that you need the synonym dictionary as well as the normalize function\n",
    "\n",
    "def detect_paraphrase(phrase_1, phrase_2):\n",
    "    \n",
    "    phrase_1 = normalize(phrase_1)\n",
    "    phrase_2 = normalize(phrase_2)\n",
    "    \n",
    "    phrase_1 = [stemmer.stem(i) for i in phrase_1]\n",
    "    phrase_2 = [stemmer.stem(i) for i in phrase_2]\n",
    "    \n",
    "    n = 0\n",
    "    i = 0\n",
    "    for u in phrase_1:\n",
    "        if phrase_2[i] in synonyms[u]:\n",
    "            n += 1\n",
    "        elif u == phrase_2[i]:\n",
    "            n += 1\n",
    "        i += 1\n",
    "    \n",
    "    chance = n / len(phrase_1)\n",
    "    \n",
    "    print('%.1f' % (round(chance, 2) * 100) + \"% likely to be a paraphrase...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "sacred-development",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.0% likely to be a paraphrase...\n"
     ]
    }
   ],
   "source": [
    "# Let's test this out\n",
    "\n",
    "detect_paraphrase('I love you!', 'I like you!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "coupled-tooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% likely to be a paraphrase...\n"
     ]
    }
   ],
   "source": [
    "detect_paraphrase(\"Your parents are bad people.\", \"I think that you're funny!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "correct-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.0% likely to be a paraphrase...\n"
     ]
    }
   ],
   "source": [
    "# Now, what happens when the phrases are a different length?\n",
    "\n",
    "detect_paraphrase(\"I love you!\", \"I just got back from the gym.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "coral-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we're seeing a 33% match here because the first phrase is of length 3 and the first word matches. Probably not a paraphrase.\n",
    "# It's probably a good idea to make it more mathematical. Let's change up our detect_paraphrase function.\n",
    "\n",
    "def detect_paraphrase(phrase_1, phrase_2):\n",
    "    \n",
    "    phrase_1 = normalize(phrase_1)\n",
    "    phrase_2 = normalize(phrase_2)\n",
    "    \n",
    "    phrase_1 = [stemmer.stem(i) for i in phrase_1]\n",
    "    phrase_2 = [stemmer.stem(i) for i in phrase_2]\n",
    "    \n",
    "    n = 0\n",
    "    i = len(phrase_1) if len(phrase_1) > len(phrase_2) else len(phrase_2)\n",
    "    for token in range(i):\n",
    "        try:\n",
    "            if phrase_2[token] in synonyms[phrase_1[token]]:\n",
    "                n += 1\n",
    "            elif phrase_1[token] == phrase_2[token]:\n",
    "                n += 1\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    chance = n / i\n",
    "    \n",
    "    print('%.1f' % (round(chance, 2) * 100) + \"% likely to be a paraphrase...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "imposed-briefing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0% likely to be a paraphrase...\n"
     ]
    }
   ],
   "source": [
    "detect_paraphrase(\"I love you!\", \"I just got back from the gym.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "plastic-mozambique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0% likely to be a paraphrase...\n"
     ]
    }
   ],
   "source": [
    "# Now we're getting somewhere! Let's keep testing!\n",
    "\n",
    "detect_paraphrase(\"The boy hit the ball\", \"The kid hit the ball\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "passive-radical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0% likely to be a paraphrase...\n"
     ]
    }
   ],
   "source": [
    "detect_paraphrase(\"You might like champagne\", \"You may fancy champagne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "signed-flashing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% likely to be a paraphrase...\n"
     ]
    }
   ],
   "source": [
    "detect_paraphrase(\"I think you're on to something!\", \"You're definitely headed in the right direction!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "authentic-dallas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.0% likely to be a paraphrase...\n"
     ]
    }
   ],
   "source": [
    "detect_paraphrase(\"We can try to do it\", \"We are able to try\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "buried-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So here we see something that we have not yet accounted for. Just because a word is not at the same location as a word in another phrase does not mean that they are not paraphrases.\n",
    "# Let's try something new and test it out.\n",
    "\n",
    "# So we're seeing a 33% match here because the first phrase is of length 3 and the first word matches. Probably not a paraphrase.\n",
    "# It's probably a good idea to make it more mathematical. Let's change up our detect_paraphrase function.\n",
    "\n",
    "def detect_paraphrase(phrase_1, phrase_2):\n",
    "    \n",
    "    phrase_1 = normalize(phrase_1)\n",
    "    phrase_2 = normalize(phrase_2)\n",
    "    \n",
    "    phrase_1 = [stemmer.stem(i) for i in phrase_1]\n",
    "    phrase_2 = [stemmer.stem(i) for i in phrase_2]\n",
    "    \n",
    "    n = 0\n",
    "    i = len(phrase_1) if len(phrase_1) > len(phrase_2) else len(phrase_2)\n",
    "    #print(phrase_1)\n",
    "    #print(phrase_2)\n",
    "    \n",
    "    if len(phrase_1) > len(phrase_2):\n",
    "        for word in phrase_1:\n",
    "            if synonyms[word] in phrase_2:\n",
    "                n += 1\n",
    "            elif word in phrase_2:\n",
    "                n += 1\n",
    "    else:\n",
    "        for word in phrase_2:\n",
    "            if synonyms[word] in phrase_1:\n",
    "                n += 1\n",
    "            elif word in phrase_1:\n",
    "                n += 1\n",
    "\n",
    "    chance = n / i\n",
    "    \n",
    "    print('%.1f' % (round(chance, 3) * 100) + \"% likely to be a paraphrase...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "egyptian-third",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.7% likely to be a paraphrase...\n"
     ]
    }
   ],
   "source": [
    "detect_paraphrase(\"We can try to do it\", \"We are able to try it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "every-nursery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.3% likely to be a paraphrase...\n"
     ]
    }
   ],
   "source": [
    "detect_paraphrase(\"We might be able to do it\", \"We are trying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "surrounded-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is acceptable... The first example is not present progressive while phrase_2 is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "continuous-penguin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0% likely to be a paraphrase...\n"
     ]
    }
   ],
   "source": [
    "detect_paraphrase(\"We're working on it\", \"We're attempting it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-montana",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
